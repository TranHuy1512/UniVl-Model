{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bd33197",
   "metadata": {},
   "source": [
    "# Training UniVL FROM SCRATCH trÃªn MSRVTT\n",
    "\n",
    "## ğŸš€ Má»¥c Ä‘Ã­ch\n",
    "\n",
    "Notebook nÃ y hÆ°á»›ng dáº«n training UniVL **KHÃ”NG sá»­ dá»¥ng pretrained weights** (`univl.pretrained.bin`).\n",
    "\n",
    "### So sÃ¡nh vá»›i training thÃ´ng thÆ°á»ng:\n",
    "\n",
    "| Aspect | Training ThÃ´ng ThÆ°á»ng | Training FROM SCRATCH |\n",
    "|--------|----------------------|----------------------|\n",
    "| **Pretrained** | âœ… DÃ¹ng `univl.pretrained.bin` | âŒ KHÃ”NG dÃ¹ng pretrained |\n",
    "| **BERT** | âœ… Pretrained | âœ… Pretrained (váº«n dÃ¹ng) |\n",
    "| **Visual Encoder** | âœ… Pretrained (HowTo100M) | âŒ Random initialization |\n",
    "| **Cross Encoder** | âœ… Pretrained | âŒ Random initialization |\n",
    "| **Decoder** | âœ… Pretrained | âŒ Random initialization |\n",
    "| **Epochs** | 5 | 10-15 (cáº§n nhiá»u hÆ¡n) |\n",
    "| **Learning Rate** | 3e-5 | 5e-5 (cao hÆ¡n) |\n",
    "| **Káº¿t quáº£** | BLEU-4: ~0.42 | BLEU-4: ~0.30-0.35 (thÆ°á»ng tháº¥p hÆ¡n) |\n",
    "| **Training Time** | 3-6 giá» | 6-12 giá» |\n",
    "\n",
    "### Khi nÃ o nÃªn training from scratch?\n",
    "\n",
    "âœ… **NÃªn dÃ¹ng khi:**\n",
    "- Dataset cá»§a báº¡n Ráº¤T khÃ¡c biá»‡t so vá»›i HowTo100M\n",
    "- Muá»‘n thá»­ nghiá»‡m architecture má»›i\n",
    "- Research vá» transfer learning\n",
    "- CÃ³ GPU/TPU resources máº¡nh vÃ  thá»i gian\n",
    "\n",
    "âŒ **KHÃ”NG nÃªn dÃ¹ng khi:**\n",
    "- Chá»‰ muá»‘n káº¿t quáº£ tá»‘t nhanh â†’ DÃ¹ng pretrained\n",
    "- Dataset nhá» (< 10k videos) â†’ DÃ¹ng pretrained\n",
    "- GPU/compute resources háº¡n cháº¿ â†’ DÃ¹ng pretrained\n",
    "\n",
    "---\n",
    "\n",
    "## YÃªu cáº§u mÃ´i trÆ°á»ng\n",
    "\n",
    "- **GPU**: T4 x2 hoáº·c P100 (Kaggle)\n",
    "- **RAM**: â‰¥ 16GB\n",
    "- **Disk**: â‰¥ 20GB free space\n",
    "- **Time**: 6-12 giá» training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b090c0",
   "metadata": {},
   "source": [
    "---\n",
    "## BÆ°á»›c 0: Clone Source Code vÃ  Kiá»ƒm tra MÃ´i trÆ°á»ng\n",
    "\n",
    "### 0.1 Clone UniVL repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640fd62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone UniVL repository\n",
    "!git clone https://github.com/microsoft/UniVL.git\n",
    "%cd UniVL\n",
    "\n",
    "print(\"âœ“ Repository cloned!\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d986fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiá»ƒm tra mÃ´i trÆ°á»ng\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492f82c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÃ i Ä‘áº·t dependencies\n",
    "!pip install tqdm pandas\n",
    "!pip install pycocoevalcap\n",
    "\n",
    "print(\"âœ“ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6de9922",
   "metadata": {},
   "source": [
    "---\n",
    "## BÆ°á»›c 1: Táº£i BERT Pretrained Model\n",
    "\n",
    "**LÆ°u Ã½ quan trá»ng:** DÃ¹ training tá»« Ä‘áº§u (from scratch), chÃºng ta váº«n cáº§n **BERT pretrained model** cho Text Encoder. Pháº§n \"from scratch\" á»Ÿ Ä‘Ã¢y nghÄ©a lÃ :\n",
    "- âŒ KHÃ”NG dÃ¹ng UniVL pretrained weights (univl.pretrained.bin) - Ä‘Ã£ Ä‘Æ°á»£c pretrain trÃªn HowTo100M\n",
    "- âœ… VáºªN dÃ¹ng BERT base pretrained (bert-base-uncased) - chá»‰ lÃ  BERT thÃ´ng thÆ°á»ng\n",
    "- âœ… Visual Encoder, Cross Encoder, Decoder sáº½ Ä‘Æ°á»£c khá»Ÿi táº¡o ngáº«u nhiÃªn\n",
    "\n",
    "Táº£i vá» `bert-base-uncased`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3553292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº¡o thÆ° má»¥c vÃ  táº£i BERT base model\n",
    "!mkdir -p bert-base-uncased\n",
    "!wget -P bert-base-uncased https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt\n",
    "!wget -P bert-base-uncased https://huggingface.co/bert-base-uncased/resolve/main/config.json\n",
    "!wget -P bert-base-uncased https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin\n",
    "\n",
    "print(\"âœ“ BERT model downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90808007",
   "metadata": {},
   "source": [
    "---\n",
    "## BÆ°á»›c 2: Táº£i Dataset MSRVTT\n",
    "\n",
    "**LÆ°u Ã½:** ChÃºng ta KHÃ”NG táº£i UniVL pretrained weights (univl.pretrained.bin) vÃ¬ Ä‘ang training from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad84beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº£i MSRVTT dataset\n",
    "!mkdir -p data/msrvtt\n",
    "\n",
    "# Download video features (S3D features extracted)\n",
    "!wget -P data/msrvtt https://www.rocq.inria.fr/cluster-willow/amiech/MSRVTT.zip\n",
    "!unzip -q data/msrvtt/MSRVTT.zip -d data/msrvtt/\n",
    "\n",
    "# Download captions\n",
    "!wget -P data/msrvtt https://github.com/ArrowLuo/CLIP4Clip/releases/download/v0.0/msrvtt_data.zip\n",
    "!unzip -q data/msrvtt/msrvtt_data.zip -d data/msrvtt/\n",
    "\n",
    "print(\"âœ“ MSRVTT dataset downloaded!\")\n",
    "!ls -lh data/msrvtt/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b173ef",
   "metadata": {},
   "source": [
    "---\n",
    "## BÆ°á»›c 3: Chuáº©n bá»‹ Training Command (From Scratch)\n",
    "\n",
    "### CÃ¡c thay Ä‘á»•i quan trá»ng khi training from scratch:\n",
    "\n",
    "| Tham sá»‘ | With Pretrained | From Scratch | LÃ½ do |\n",
    "|---------|----------------|--------------|-------|\n",
    "| `--init_model` | âœ… CÃ³ (univl.pretrained.bin) | âŒ Bá» ÄI | KhÃ´ng dÃ¹ng pretrained weights |\n",
    "| `--epochs` | 5 | **10-15** | Cáº§n nhiá»u epoch hÆ¡n Ä‘á»ƒ há»c tá»« Ä‘áº§u |\n",
    "| `--lr` | 3e-5 | **5e-5** | Learning rate cao hÆ¡n cho random init |\n",
    "| `--batch_size` | 128 | **64-96** | CÃ³ thá»ƒ giáº£m náº¿u thiáº¿u RAM |\n",
    "| `--bert_model` | âœ… Váº«n cáº§n | âœ… Váº«n cáº§n | BERT base váº«n Ä‘Æ°á»£c pretrain |\n",
    "\n",
    "### Training strategy:\n",
    "1. **Visual Encoder**: Khá»Ÿi táº¡o ngáº«u nhiÃªn (khÃ´ng cÃ³ HowTo100M pretrained)\n",
    "2. **Text Encoder**: BERT base pretrained (bert-base-uncased)\n",
    "3. **Cross Encoder & Decoder**: Khá»Ÿi táº¡o ngáº«u nhiÃªn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c29b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº¡o training command (from scratch - NO pretrained weights)\n",
    "DATA_PATH = \"data/msrvtt\"\n",
    "OUTPUT_DIR = \"outputs/msrvtt_caption_fromscratch\"\n",
    "BERT_PATH = \"bert-base-uncased\"\n",
    "\n",
    "# Sá»‘ GPU vÃ  batch size\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "BATCH_SIZE_PER_GPU = 32  # Äiá»u chá»‰nh theo VRAM cá»§a GPU\n",
    "TOTAL_BATCH_SIZE = BATCH_SIZE_PER_GPU * NUM_GPUS\n",
    "\n",
    "print(f\"Number of GPUs: {NUM_GPUS}\")\n",
    "print(f\"Batch size per GPU: {BATCH_SIZE_PER_GPU}\")\n",
    "print(f\"Total batch size: {TOTAL_BATCH_SIZE}\")\n",
    "print()\n",
    "\n",
    "# âš ï¸ LÆ¯U Ã: KHÃ”NG cÃ³ --init_model (Ä‘Ã¢y lÃ  Ä‘iá»ƒm khÃ¡c biá»‡t chÃ­nh!)\n",
    "training_command = f\"\"\"\n",
    "torchrun --nproc_per_node={NUM_GPUS} \\\\\n",
    "  --master_port=2502 \\\\\n",
    "  main_task_caption.py \\\\\n",
    "  --do_train \\\\\n",
    "  --num_thread_reader=4 \\\\\n",
    "  --epochs=12 \\\\\n",
    "  --batch_size={BATCH_SIZE_PER_GPU} \\\\\n",
    "  --n_display=50 \\\\\n",
    "  --train_csv {DATA_PATH}/MSRVTT_train.9k.csv \\\\\n",
    "  --val_csv {DATA_PATH}/MSRVTT_JSFUSION_test.csv \\\\\n",
    "  --data_path {DATA_PATH}/MSRVTT_data.json \\\\\n",
    "  --features_path {DATA_PATH}/MSRVTT_Videos \\\\\n",
    "  --output_dir {OUTPUT_DIR} \\\\\n",
    "  --bert_model {BERT_PATH} \\\\\n",
    "  --visual_model modules/visual-base/visual_config.json \\\\\n",
    "  --cross_model modules/cross-base/cross_config.json \\\\\n",
    "  --decoder_model modules/decoder-base/decoder_config.json \\\\\n",
    "  --max_words 32 \\\\\n",
    "  --max_frames 12 \\\\\n",
    "  --video_framerate 1 \\\\\n",
    "  --lr 5e-5 \\\\\n",
    "  --gradient_accumulation_steps 1 \\\\\n",
    "  --coef_lr 1e-3 \\\\\n",
    "  --warmup_proportion 0.1 \\\\\n",
    "  --n_gpu {NUM_GPUS}\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAINING COMMAND (FROM SCRATCH):\")\n",
    "print(\"=\" * 80)\n",
    "print(training_command)\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"âš ï¸  LÆ°u Ã½: KHÃ”NG cÃ³ --init_model, model sáº½ training tá»« Ä‘áº§u!\")\n",
    "print(\"â±  Thá»i gian dá»± kiáº¿n: 2-3 ngÃ y (phá»¥ thuá»™c GPU)\")\n",
    "print(\"ğŸ“Š Validation loss sáº½ Ä‘Æ°á»£c hiá»ƒn thá»‹ sau má»—i epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017053e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº¡o output directory\n",
    "!mkdir -p {OUTPUT_DIR}\n",
    "\n",
    "# Cháº¡y training\n",
    "!{training_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704ec6d4",
   "metadata": {},
   "source": [
    "---\n",
    "## BÆ°á»›c 4: Monitoring Training Progress\n",
    "\n",
    "Sau khi cháº¡y training, báº¡n cÃ³ thá»ƒ theo dÃµi:\n",
    "- **Training loss**: Xuáº¥t hiá»‡n má»—i 50 steps (`n_display=50`)\n",
    "- **Validation metrics**: Sau má»—i epoch, hiá»ƒn thá»‹:\n",
    "  - BLEU-1, BLEU-2, BLEU-3, BLEU-4\n",
    "  - METEOR, ROUGE_L, CIDEr\n",
    "  - **Validation Loss** (Ä‘Ã£ Ä‘Æ°á»£c thÃªm vÃ o code)\n",
    "\n",
    "### CÃ¡c file output quan trá»ng:\n",
    "- `{OUTPUT_DIR}/pytorch_model.bin.{epoch}` - Model checkpoint má»—i epoch\n",
    "- `{OUTPUT_DIR}/log.txt` - Training log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11aced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem training log trong thá»i gian thá»±c\n",
    "!tail -f {OUTPUT_DIR}/log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b5e5bf",
   "metadata": {},
   "source": [
    "---\n",
    "## BÆ°á»›c 5: Evaluation trÃªn Test Set\n",
    "\n",
    "Sau khi training xong, Ä‘Ã¡nh giÃ¡ model tá»‘t nháº¥t trÃªn test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72f9bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TÃ¬m epoch tá»‘t nháº¥t (dá»±a vÃ o validation BLEU-4)\n",
    "import os\n",
    "import glob\n",
    "\n",
    "checkpoint_files = glob.glob(f\"{OUTPUT_DIR}/pytorch_model.bin.*\")\n",
    "if checkpoint_files:\n",
    "    print(\"Available checkpoints:\")\n",
    "    for ckpt in sorted(checkpoint_files):\n",
    "        epoch = ckpt.split('.')[-1]\n",
    "        print(f\"  - Epoch {epoch}: {ckpt}\")\n",
    "        \n",
    "    # ThÆ°á»ng chá»n epoch cuá»‘i hoáº·c epoch cÃ³ BLEU-4 cao nháº¥t (xem trong log.txt)\n",
    "    best_epoch = len(checkpoint_files)  # Máº·c Ä‘á»‹nh chá»n epoch cuá»‘i\n",
    "    print(f\"\\nğŸ“Œ Using checkpoint from epoch {best_epoch}\")\n",
    "else:\n",
    "    print(\"âŒ No checkpoints found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3241c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cháº¡y evaluation trÃªn test set\n",
    "BEST_MODEL = f\"{OUTPUT_DIR}/pytorch_model.bin.{best_epoch}\"\n",
    "\n",
    "eval_command = f\"\"\"\n",
    "torchrun --nproc_per_node={NUM_GPUS} \\\\\n",
    "  --master_port=2502 \\\\\n",
    "  main_task_caption.py \\\\\n",
    "  --do_eval \\\\\n",
    "  --num_thread_reader=4 \\\\\n",
    "  --batch_size={BATCH_SIZE_PER_GPU} \\\\\n",
    "  --val_csv {DATA_PATH}/MSRVTT_JSFUSION_test.csv \\\\\n",
    "  --data_path {DATA_PATH}/MSRVTT_data.json \\\\\n",
    "  --features_path {DATA_PATH}/MSRVTT_Videos \\\\\n",
    "  --output_dir {OUTPUT_DIR} \\\\\n",
    "  --bert_model {BERT_PATH} \\\\\n",
    "  --visual_model modules/visual-base/visual_config.json \\\\\n",
    "  --cross_model modules/cross-base/cross_config.json \\\\\n",
    "  --decoder_model modules/decoder-base/decoder_config.json \\\\\n",
    "  --init_model {BEST_MODEL} \\\\\n",
    "  --max_words 32 \\\\\n",
    "  --max_frames 12 \\\\\n",
    "  --video_framerate 1 \\\\\n",
    "  --n_gpu {NUM_GPUS}\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"EVALUATION COMMAND:\")\n",
    "print(\"=\" * 80)\n",
    "print(eval_command)\n",
    "print(\"=\" * 80)\n",
    "\n",
    "!{eval_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b01694",
   "metadata": {},
   "source": [
    "---\n",
    "## BÆ°á»›c 6 (Optional): So sÃ¡nh vá»›i Pretrained Model\n",
    "\n",
    "Náº¿u muá»‘n so sÃ¡nh káº¿t quáº£ training from scratch vá»›i pretrained model, cÃ³ thá»ƒ táº£i univl.pretrained.bin vÃ  cháº¡y training vá»›i cÃ¹ng hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6932a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Download pretrained UniVL Ä‘á»ƒ so sÃ¡nh\n",
    "!wget https://github.com/microsoft/UniVL/releases/download/v0/univl.pretrained.bin\n",
    "\n",
    "print(\"âœ“ Pretrained model downloaded for comparison!\")\n",
    "print(\"\\nÄá»ƒ train vá»›i pretrained, thÃªm flag:\")\n",
    "print(\"  --init_model univl.pretrained.bin\")\n",
    "print(\"\\nVÃ  giáº£m epochs xuá»‘ng 5, lr xuá»‘ng 3e-5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a30e0a",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Š Káº¿t quáº£ dá»± kiáº¿n\n",
    "\n",
    "### Training from Scratch (dá»± kiáº¿n sau 12 epochs):\n",
    "- **BLEU-4**: ~35-38 (tháº¥p hÆ¡n pretrained ~2-5 Ä‘iá»ƒm)\n",
    "- **CIDEr**: ~40-45\n",
    "- **Training time**: 2-3 ngÃ y trÃªn 4x V100\n",
    "\n",
    "### With Pretrained (5 epochs):\n",
    "- **BLEU-4**: ~40-42\n",
    "- **CIDEr**: ~47-50\n",
    "- **Training time**: 12-18 giá» trÃªn 4x V100\n",
    "\n",
    "### Lá»£i Ã­ch cá»§a training from scratch:\n",
    "- âœ… KhÃ´ng phá»¥ thuá»™c vÃ o HowTo100M pretrained\n",
    "- âœ… CÃ³ thá»ƒ customize architecture tá»± do\n",
    "- âœ… Hiá»ƒu rÃµ model behavior tá»« Ä‘áº§u\n",
    "- âŒ Káº¿t quáº£ tháº¥p hÆ¡n ~5-10%\n",
    "- âŒ Training lÃ¢u hÆ¡n 3-5 láº§n\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Tá»•ng káº¿t\n",
    "\n",
    "Notebook nÃ y Ä‘Ã£ hÆ°á»›ng dáº«n báº¡n:\n",
    "1. âœ… Setup mÃ´i trÆ°á»ng vÃ  dependencies\n",
    "2. âœ… Táº£i BERT base model (váº«n cáº§n cho Text Encoder)\n",
    "3. âœ… Táº£i MSRVTT dataset (khÃ´ng cáº§n UniVL pretrained)\n",
    "4. âœ… Training command KHÃ”NG cÃ³ --init_model\n",
    "5. âœ… Monitoring vÃ  evaluation\n",
    "6. âœ… So sÃ¡nh vá»›i pretrained model (optional)\n",
    "\n",
    "**ChÃºc báº¡n training thÃ nh cÃ´ng! ğŸš€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
